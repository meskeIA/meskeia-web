'use client';

import ChapterPage from '../../ChapterPage';
import styles from '../../CursoOptimizacionIA.module.css';

export default function LLMsRAGPage() {
  return (
    <ChapterPage chapterId="llms-rag">
      {/* Introducci칩n */}
      <section className={styles.contentSection}>
        <div className={styles.sectionHeader}>
          <span className={styles.sectionIcon}>游</span>
          <h2 className={styles.sectionTitleText}>Introducci칩n</h2>
        </div>
        <p>
          En el panorama digital de 2025, comprender c칩mo las inteligencias artificiales generativas
          seleccionan y citan contenido se ha convertido en una habilidad estrat칠gica cr칤tica para
          cualquier creador de contenido. Los Large Language Models (LLMs) han transformado radicalmente
          la forma en que se consume informaci칩n, procesando m치s de 1.3 billones de consultas mensuales
          en motores de respuesta como ChatGPT, Perplexity y Claude.
        </p>
        <p>
          Este cap칤tulo te revelar치 los mecanismos internos que determinan qu칠 fuentes son consideradas
          relevantes y autoritativas en el ecosistema de las IAs generativas, bas치ndose en patrones de
          citaci칩n documentados en 2024 y tendencias emergentes para 2025.
        </p>
      </section>

      {/* LLMs */}
      <section className={styles.contentSection}>
        <div className={styles.sectionHeader}>
          <span className={styles.sectionIcon}>游뱄</span>
          <h2 className={styles.sectionTitleText}>Los Large Language Models: El Cerebro Digital de la IA</h2>
        </div>
        <p>
          Los Large Language Models representan sistemas computacionales complejos basados en redes
          neuronales profundas entrenadas con billones de par치metros textuales. A diferencia de los
          algoritmos tradicionales de b칰squeda que se basan en coincidencias de palabras clave, estos
          sistemas desarrollan una comprensi칩n sem치ntica profunda que les permite interpretar intenciones,
          contextos culturales y matices ling칲칤sticos espec칤ficos del espa침ol latinoamericano.
        </p>
        <p>
          En su arquitectura fundamental, estos modelos funcionan mediante <strong>transformers</strong>,
          una tecnolog칤a revolucionaria que permite analizar secuencias completas de texto de manera
          simult치nea. El modelo GPT-4 Turbo, lanzado en 2024, procesa hasta 128,000 tokens de contexto,
          equivalente a aproximadamente 300 p치ginas de texto, mientras que Claude-3 Opus puede manejar
          contextos de hasta 200,000 tokens.
        </p>
        <p>
          Lo que hace especialmente relevante a estos sistemas para creadores de contenido es su capacidad
          de evaluaci칩n de autoridad tem치tica. Los LLMs no solo analizan palabras clave, sino que eval칰an
          la coherencia argumentativa, la profundidad del an치lisis, la precisi칩n de los datos citados y
          la originalidad de las perspectivas presentadas.
        </p>

        <div className={styles.highlightBox}>
          <p>
            Un estudio de Stanford de 2024 revel칩 que contenido con citas acad칠micas tiene
            <strong> 340% m치s probabilidades</strong> de ser referenciado por IAs generativas.
          </p>
        </div>

        <p>
          La evoluci칩n reciente ha introducido capacidades multimodales avanzadas, donde modelos como
          GPT-4V y Gemini Ultra pueden integrar informaci칩n de gr치ficos, tablas, infograf칤as y documentos PDF.
          Para el mercado hispanohablante, esto significa que contenido visualmente rico, con datos
          estructurados y an치lisis multidimensional, obtiene ventajas significativas en procesos de
          selecci칩n y citaci칩n.
        </p>

        <div className={styles.exampleBox}>
          <p>
            <strong>Ejemplo:</strong> Un informe sobre fintech en M칠xico que incluya gr치ficos de adopci칩n
            digital, citas del Banco de M칠xico, an치lisis comparativo con Brasil y Argentina, y proyecciones
            respaldadas por consultoras como McKinsey, ser치 citado consistentemente por modelos como
            Perplexity AI frente a art칤culos gen칠ricos sobre el tema.
          </p>
        </div>
      </section>

      {/* RAG */}
      <section className={styles.contentSection}>
        <div className={styles.sectionHeader}>
          <span className={styles.sectionIcon}>游댌</span>
          <h2 className={styles.sectionTitleText}>RAG: El Motor de B칰squeda Inteligente</h2>
        </div>
        <p>
          Retrieval-Augmented Generation representa la evoluci칩n m치s significativa en sistemas de b칰squeda
          desde el PageRank de Google. A diferencia de modelos tradicionales que dependen 칰nicamente de
          su entrenamiento, los sistemas RAG ejecutan b칰squedas en tiempo real, eval칰an m칰ltiples fuentes
          y construyen respuestas contextualizadas con referencias verificables.
        </p>

        <div className={styles.highlightBox}>
          <p>
            En 2024, m치s del <strong>78%</strong> de las respuestas generadas por ChatGPT con navegaci칩n
            web utilizan arquitectura RAG.
          </p>
        </div>

        <h3>Las 5 Etapas del Proceso RAG</h3>
        <ol>
          <li><strong>Query Understanding</strong> - Comprensi칩n de la consulta: el sistema interpreta la intenci칩n y contexto</li>
          <li><strong>Retrieval</strong> - Recuperaci칩n: busca informaci칩n relevante en bases de datos actualizadas</li>
          <li><strong>Relevance Scoring</strong> - Puntuaci칩n: eval칰a la calidad y pertinencia de cada fuente</li>
          <li><strong>Re-ranking</strong> - Re-clasificaci칩n: prioriza fuentes bas치ndose en autoridad y actualidad</li>
          <li><strong>Generation</strong> - Generaci칩n final: construye una respuesta coherente integrando m칰ltiples fuentes</li>
        </ol>

        <p>
          Los algoritmos de puntuaci칩n en sistemas RAG eval칰an factores espec칤ficos: <em>domain authority</em>,
          <em>freshness score</em>, <em>citation density</em>, <em>semantic relevance</em> y
          <em>user engagement metrics</em>.
        </p>

        <div className={styles.highlightBox}>
          <p>
            Una investigaci칩n de MIT de 2024 identific칩 que contenido publicado en dominios con autoridad
            superior a 70 (seg칰n Ahrefs) tiene <strong>450% m치s probabilidades</strong> de citaci칩n.
          </p>
        </div>

        <p>
          Para el ecosistema de contenido en espa침ol, los sistemas RAG han desarrollado capacidades espec칤ficas
          de reconocimiento de autoridades regionales. Fuentes como universidades latinoamericanas prestigiosas,
          instituciones gubernamentales oficiales, medios establecidos y expertos con credenciales verificables
          reciben ponderaciones superiores.
        </p>

        <div className={styles.exampleBox}>
          <p>
            <strong>Ejemplo:</strong> Un an치lisis sobre inflaci칩n en Argentina que cite datos del INDEC,
            incluya perspectivas del BCRA, referencias a economistas reconocidos como Mart칤n Guzm치n, y
            compare con indicadores del FMI, ser치 sistem치ticamente preferido por sistemas RAG frente a
            an치lisis gen칠ricos sin fuentes locales verificables.
          </p>
        </div>
      </section>

      {/* Ideas Clave */}
      <div className={styles.keyIdeasList}>
        <h4>游눠 Ideas Clave</h4>
        <ul>
          <li>Los LLMs procesan hasta 200,000 tokens de contexto, evaluando autoridad tem치tica y coherencia argumentativa</li>
          <li>RAG ejecuta b칰squedas en tiempo real con cinco etapas de evaluaci칩n y re-ranking de fuentes</li>
          <li>Contenido con citas acad칠micas tiene 340% m치s probabilidades de ser referenciado por IAs</li>
          <li>Dominios con autoridad superior a 70 obtienen 450% m치s citaciones en sistemas RAG</li>
          <li>Los algoritmos favorecen fuentes que demuestran comprensi칩n de contextos culturales espec칤ficos</li>
        </ul>
      </div>

      {/* Acciones */}
      <div className={styles.practicalTip}>
        <h4>游꿢 Acciones para Implementar Hoy</h4>
        <ul>
          <li>Implementa un sistema de citaci칩n acad칠mica en tus art칤culos, incluyendo al menos 5 referencias verificables por cada 1,000 palabras</li>
          <li>Crea contenido multimodal integrando gr치ficos con datos de fuentes oficiales como bancos centrales, universidades o instituciones gubernamentales</li>
          <li>Desarrolla una matriz de autoridad tem치tica identificando 10 expertos reconocidos en tu nicho y establece menciones estrat칠gicas</li>
          <li>Configura alertas en Google Scholar y bases de datos acad칠micas para incorporar investigaciones recientes (칰ltimos 12 meses)</li>
          <li>Estructura tu contenido con headers sem치nticos (H1-H4) y implementa schema markup para facilitar el procesamiento por sistemas RAG</li>
        </ul>
      </div>

      {/* Reflexi칩n */}
      <div className={styles.reflectionQuestions}>
        <h4>游뱂 Preguntas de Reflexi칩n</h4>
        <ol>
          <li>쯄i contenido incluye al menos 5 fuentes verificables y actualizadas en los 칰ltimos 12 meses?</li>
          <li>쮼stoy citando autoridades locales reconocidas en mi regi칩n o industria espec칤fica?</li>
          <li>쯄is art칤culos ofrecen datos 칰nicos o perspectivas originales que no se encuentran en competidores directos?</li>
          <li>쯊engo implementado schema markup y estructura sem치ntica que facilite el procesamiento por IAs?</li>
          <li>쯄i autoridad de dominio supera el umbral de 70 puntos seg칰n herramientas como Ahrefs o Semrush?</li>
        </ol>
      </div>

      {/* Recursos */}
      <section className={styles.contentSection}>
        <div className={styles.sectionHeader}>
          <span className={styles.sectionIcon}>游댢</span>
          <h2 className={styles.sectionTitleText}>Recursos Recomendados</h2>
        </div>
        <ul>
          <li><strong>Perplexity AI Pro</strong> - Para an치lisis de patrones de citaci칩n</li>
          <li><strong>Google Scholar Alerts</strong> - Para monitoreo de investigaciones recientes</li>
          <li><strong>Ahrefs Content Gap</strong> - Para identificar oportunidades de autoridad tem치tica</li>
          <li><strong>Schema.org Markup Generator</strong> - Para estructura sem치ntica</li>
          <li><strong>Answer The Public</strong> - Para identificar consultas emergentes en espa침ol</li>
        </ul>
      </section>

      {/* Curiosidad */}
      <div className={styles.curiosityBox}>
        <h4>游눠 쯉ab칤as que...?</h4>
        <p>
          En 2024, Anthropic document칩 que Claude-3 puede procesar el equivalente a &quot;El Quijote&quot;
          completo en una sola consulta (200,000 tokens), permitiendo an치lisis contextuales de documentos
          extensos que superan la capacidad de comprensi칩n de sistemas tradicionales de b칰squeda por
          factores exponenciales.
        </p>
      </div>
    </ChapterPage>
  );
}
